{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1NvamTqXF4oaPEarcPln3k5wQgo5h-x1n","authorship_tag":"ABX9TyNs2HT8iT8Gv9kN1eWz3phl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HDjdzMAq-MZc"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    EvalPrediction\n",")\n","from sklearn.metrics import accuracy_score\n","from transformers import TrainerCallback\n","\n","\n","# GPU 사용 가능 확인 및 device 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","# SentimentDataset 클래스 정의\n","class SentimentDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# CSV 파일 로드\n","df = pd.read_csv('path')  # hr_data\n","# 데이터 전처리\n","texts = df['person_corpus'].tolist()\n","labels = df['label'].tolist()  # 라벨 데이터는 정수로 변환되어 있어야 합니다.\n","\n","# 토크나이저 로딩\n","tokenizer_roberta = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n","tokenizer_electra = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n","\n","# 데이터셋 토큰화\n","encodings_roberta = tokenizer_roberta(texts, truncation=True, padding=True, max_length=128)\n","encodings_electra = tokenizer_electra(texts, truncation=True, padding=True, max_length=128)\n","\n","# 데이터셋 생성\n","dataset_roberta = SentimentDataset(encodings_roberta, labels)\n","dataset_electra = SentimentDataset(encodings_electra, labels)\n","\n","\n","# 로드할 RoBERTa 모델 경로\n","roberta_model_path = \"path\"\n","# 로드할 Electra 모델 경로\n","electra_model_path = \"path\"\n","\n","# 저장된 모델 로드\n","model_roberta = AutoModelForSequenceClassification.from_pretrained(roberta_model_path)\n","model_electra = AutoModelForSequenceClassification.from_pretrained(electra_model_path)\n","\n","# CustomTrainer 클래스 정의\n","class CustomTrainer(Trainer):\n","    def __init__(self, *args, label_weights=None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.label_weights = label_weights if label_weights is not None else {}\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        outputs = model(**inputs)\n","        logits = outputs.get('logits')\n","        labels = inputs.get('labels')\n","        if self.label_weights:\n","            weight = torch.tensor([self.label_weights.get(label.item(), 1.0) for label in labels]).to(labels.device)\n","            loss_fct = CrossEntropyLoss(weight=weight)\n","        else:\n","            loss_fct = CrossEntropyLoss()\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n","# TrainingArguments 설정\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=100,\n","    per_device_train_batch_size=16,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n",")\n","\n","# 라벨별 가중치 설정\n","label_weights = {0: 8.0, 1: 2.5, 2: 5.0, 3: 1.0}\n","\n","# CustomTrainer 인스턴스 생성\n","trainer_roberta = CustomTrainer(\n","    model=model_roberta,\n","    args=training_args,\n","    train_dataset=dataset_roberta,  # dataset_roberta는 사용자가 정의해야 함\n","    label_weights=label_weights,\n",")\n","\n","trainer_electra = CustomTrainer(\n","    model=model_electra,\n","    args=training_args,\n","    train_dataset=dataset_electra,  # dataset_electra는 사용자가 정의해야 함\n","    label_weights=label_weights,\n",")\n","\n","# 로짓을 확률로 변환하는 함수\n","def logits_to_probs(logits):\n","    return torch.softmax(logits, dim=1)\n","\n","def predict_with_ensemble_modified(texts, roberta_model, koelectra_model, tokenizer_roberta, tokenizer_koelectra, device):\n","    encodings_roberta = tokenizer_roberta(texts, truncation=True, padding=True, max_length=128)\n","    encodings_koelectra = tokenizer_koelectra(texts, truncation=True, padding=True, max_length=128)\n","\n","    roberta_dataset = SentimentDataset(encodings_roberta, [0]*len(texts))  # 라벨은 예측을 위해 사용되지 않으므로 임시 값으로 설정\n","    koelectra_dataset = SentimentDataset(encodings_koelectra, [0]*len(texts))\n","\n","    roberta_dataloader = DataLoader(roberta_dataset, batch_size=32, shuffle=False)\n","    koelectra_dataloader = DataLoader(koelectra_dataset, batch_size=32, shuffle=False)\n","\n","    roberta_model.to(device)\n","    koelectra_model.to(device)\n","\n","    roberta_model.eval()\n","    koelectra_model.eval()\n","\n","    final_labels = []  # 최종 라벨을 저장할 리스트를 루프 외부에서 초기화\n","\n","    with torch.no_grad():\n","        for roberta_batch, koelectra_batch in zip(roberta_dataloader, koelectra_dataloader):\n","            roberta_input_ids, roberta_attention_mask = roberta_batch['input_ids'].to(device), roberta_batch['attention_mask'].to(device)\n","            koelectra_input_ids, koelectra_attention_mask = koelectra_batch['input_ids'].to(device), koelectra_batch['attention_mask'].to(device)\n","\n","            roberta_outputs = roberta_model(roberta_input_ids, roberta_attention_mask)\n","            koelectra_outputs = koelectra_model(koelectra_input_ids, koelectra_attention_mask)\n","\n","            roberta_probs = logits_to_probs(roberta_outputs.logits).cpu().numpy()\n","            koelectra_probs = logits_to_probs(koelectra_outputs.logits).cpu().numpy()\n","\n","            ensemble_probs = (roberta_probs + koelectra_probs) / 2\n","\n","            for probs in ensemble_probs:\n","                pred_label = np.argmax(probs)\n","                if pred_label == 1 and probs[pred_label] > 0.6:  # 긍정이면서 확률이 0.5 이상인 경우\n","                    pred_label = 3  # 매우 긍정으로 변경\n","                elif pred_label == 0 and probs[pred_label] > 0.7:  # 부정이면서 확률이 0.5 이상인 경우\n","                    pred_label = 2  # 매우 부정으로 변경\n","                final_labels.append(pred_label)  # 수정된 라벨을 최종 라벨 리스트에 추가\n","\n","    return final_labels  # 수정: 최종 라벨 리스트 반환\n","\n","# 함수 호출에 device 변수 사용\n","final_labels = predict_with_ensemble_modified(texts, model_roberta, model_electra, tokenizer_roberta, tokenizer_electra, device)\n","\n","# 결과 출력\n","for text, label in zip(texts, final_labels):\n","    print(f\"Text: {text} - Prediction: {label}\")\n"]},{"cell_type":"code","source":["!git config --global user.email 'osoryo@naver.com'\n","!git config --global user.name 'ChamsolPark'\n","\n","!git add Recommendation_Model/downstream_train.ipynb\n","!git commit -m \"Add downstream_train.ipynb to Recommendation_Model\"\n","\n","# 원격 저장소와 충돌 방지를 위해 먼저 pull\n","!git pull origin master\n","\n","# 변경 사항 push\n","!git push origin master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vaJy8H_QB8oj","executionInfo":{"status":"ok","timestamp":1715924003545,"user_tz":-540,"elapsed":925,"user":{"displayName":"‍박참솔(학부생-소프트웨어전공)","userId":"18033728826949019778"}},"outputId":"fa161849-fb80-4175-ab6e-07f60785e8ce"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: not a git repository (or any of the parent directories): .git\n","fatal: not a git repository (or any of the parent directories): .git\n","fatal: not a git repository (or any of the parent directories): .git\n","fatal: not a git repository (or any of the parent directories): .git\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kr4erA53Cq3j","executionInfo":{"status":"ok","timestamp":1715924042563,"user_tz":-540,"elapsed":10210,"user":{"displayName":"‍박참솔(학부생-소프트웨어전공)","userId":"18033728826949019778"}},"outputId":"1425c2a8-bb56-4702-d4e2-2e8f3a29ce2c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/Github/capstone-2024-35"],"metadata":{"id":"of1-wDzGCt0x"},"execution_count":null,"outputs":[]}]}